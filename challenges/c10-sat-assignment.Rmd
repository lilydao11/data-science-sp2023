---
title: "SAT and College Grades"
author: "Lily Dao"
date: 2023-04-10
output:
  github_document:
    toc: true
prerequisites:
  - e-vis00-basics
editor_options: 
  markdown: 
    wrap: 72
---

*Purpose*: How do we apply hypothesis testing to investigating data? In
this challenge you'll practice using hypothesis testing tools to make
sense of a dataset.

*Reading*: - [Harvard Study Says SATs Should Be Optional: Here's
Why](https://www.csmonitor.com/USA/USA-Update/2016/0120/Harvard-study-says-SATs-should-be-optional.-Here-s-why)
(Optional); easy-to-read news article on colleges going SAT-free -
[Norm-Referenced Tests and Race-Blind
Admissions](https://cshe.berkeley.edu/publications/norm-referenced-tests-and-race-blind-admissions-case-eliminating-sat-and-act-university)
(Optional); technical report on relationship between the SAT/ACT and
non-academic factors

*Credit*: This is based on a [case
study](http://onlinestatbook.com/2/case_studies/sat.html) originally
prepared by Emily Zitek, with data collected through the research of
Thomas MacFarland.

```{r setup}
library(tidyverse)
library(readxl)
library(broom)
library(modelr)
library(rsample)
```

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics
define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category    | Needs Improvement                                                                                                | Satisfactory                                                                                                               |
|------------------|--------------------------|----------------------------|
| Effort      | Some task **q**'s left unattempted                                                                               | All task **q**'s attempted                                                                                                 |
| Observed    | Did not document observations, or observations incorrect                                                         | Documented correct observations based on analysis                                                                          |
| Supported   | Some observations not clearly supported by analysis                                                              | All observations clearly supported by analysis (table, graph, etc.)                                                        |
| Assessed    | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support      |
| Specified   | Uses the phrase "more data are necessary" without clarification                                                  | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability                                 | Code sufficiently close to the [style guide](https://style.tidyverse.org/)                                                 |

## Due Date

<!-- ------------------------- -->

All the deliverables stated in the rubrics above are due **at midnight**
before the day of the class discussion of the challenge. See the
[Syllabus](https://docs.google.com/document/d/1qeP6DUS8Djq_A0HMllMqsSqX3a9dbcx1/edit?usp=sharing&ouid=110386251748498665069&rtpof=true&sd=true)
for more information.

*Background*: Every year about 2 million students take the Scholastic
Aptitude Test (SAT). The exam is
[controversial](http://www.nea.org/home/73288.htm) but [extremely
consequential](https://www.csmonitor.com/2004/0518/p13s01-legn.html).
There are many claims about the SAT, but we're going to look at just
one: Is the SAT predictive of scholastic performance in college? It
turns out this is a fairly complicated question to assess---we'll get an
introduction to some of the complexities.

# Obtain the Data

<!-- -------------------------------------------------- -->

### **q1** Visit the [SAT and College GPA](http://onlinestatbook.com/2/case_studies/sat.html) case study page, scroll to the bottom, and click the `Open Data with Excel` button. This will allow you to download an `xls` file. Save the file to your `data` folder, load the data as `df_sat`, and perform your "first checks" against these data. Answer the questions below:

```{r q1-task}
## TODO:
df_sat <- read_xls("./data/sat.xls")


## TODO: Do your "first checks"
df_sat %>% glimpse()
df_sat %>% summary()
df_sat
```

**Observations**:

-   Fill in the following "data dictionary"

| Column     | Meaning                                |
|------------|----------------------------------------|
| `high_GPA` | High school grade point average        |
| `math_SAT` | Math SAT score                         |
| `verb_SAT` | Verbal SAT score                       |
| `comp_GPA` | Computer science grade point average   |
| `univ_GPA` | Overall university grade point average |

-   What information do we have about these students?
    -   We have the major of these students (computer science), as well
        as their high school and university GPA. We also have their math
        and verbal SAT scores, as well as their GPA specifically in
        their major.
-   What kinds of information *do we not have* about these students?
    -   We do not have information on what classes these students took,
        whether they typically perform well on tests, if their GPAs were
        all scaled the same way (but for the sake of this challenge, I'm
        assuming that we are saying they were all scaled the same). We
        also don't have information on external circumstances that may
        cause anomalies in what we would expect from a university GPA
        vs. high school stats.
-   Based on these missing variables, what possible effects could be
    present in the data that we would have *no way of detecting*?
    -   We could see students receiving a higher GPA in university
        because they took easier courses or the opposite effect. We
        could see lower SAT scores compared to the university GPA we see
        due to a missing variable like test anxiety. We also don't have
        any idea as to what a student could be experiencing outside of
        classes or their workload that isn't academic that could cause
        their GPA to suffer.

# Analysis with Hypothesis Testing

<!-- ----------------------------------------------------------------------- -->

We're going to use two complementary approaches to analyze the data, the
first based on hypothesis testing of correlation coefficients, and the
second based on fitting a regression model and interpreting the
regression coefficients.

To simplify the analysis, let's look at a composite SAT score:

```{r compute-composite}
## NOTE: No need to edit this
df_composite <-
  df_sat %>%
  mutate(both_SAT = math_SAT + verb_SAT)
df_composite
```

## View 1: Correlations

<!-- ----------------------------------------------------------------------- -->

### **q2** Create a *single* plot that shows `univ_GPA` against *both* `high_GPA` and `both_SAT`. Visually compare the two trends.

*Hint*: One way to do this is to first *pivot* `df_composite`.

```{r q2-task}
## TODO:
df_q2 <-
  df_composite %>% 
  pivot_longer(
    names_to = "variable",
    values_to = "value",
    cols = c(high_GPA, both_SAT)
  ) %>% 
  ggplot(mapping = aes(value, univ_GPA))+
  geom_point() +
  geom_smooth() +
  facet_wrap(~variable, scales = "free_x")
df_q2
```

**Observations**:

-   What relationship do `univ_GPA` and `both_SAT` exhibit?
    -   Until about a 2.75 university GPA, SAT scores typically average
        around 1100, actually showing a small dip centered around a 2.5
        university GPA. With university GPAs greater than around 2.75,
        we see a positive relationship with SAT score. A 3.0 GPA trends
        around 1150 and a 4.0 GPA trends around 1350. In terms of the
        students and their data points, we see a positive relationship,
        but it is not notably strong, especially in the lower half of
        university GPA.
-   What relationship do `univ_GPA` and `high_GPA` exhibit?
    -   Similarly to SAT scores, highschool GPA and university GPA
        experience a positive relationship that is moderately strong.
        For a university GPA below 2.75, a student's high school GPA
        averages around 2.5, but we see GPAs almost a half point higher
        and lower than that average. It isn't until a 3.5 university GPA
        that we see the university GPA average catch up with the high
        school GPA average at around 3.5. In a loose sense, it seems
        that university GPAs tend to be lower than high school GPAs.

### Hypothesis Testing with a Correlation Coefficient

<!-- ------------------------- -->

We can use the idea of hypothesis testing with a correlation
coefficient. The idea is to set our null hypothesis to the case where
there is no correlation, and test to see if the data contradict that
perspective. Formally, the null (H0) and alternative (HA) hypotheses
relating to a correlation coefficient between two variables `X, Y` are:

$$\text{H0: } \text{Corr}[X, Y] = 0$$

$$\text{HA: } \text{Corr}[X, Y] \neq 0$$

The R function `cor.test` implements such a hypothesis test under the
assumption that `X, Y` are both normally distributed. First, let's check
to see if this assumption looks reasonable for our data.

### **q3** Plot histograms for `both_SAT, high_GPA, univ_GPA`. Which---if any---of the variables look approximately normally distributed.

```{r q3-task}
histo_SAT <-
  df_composite %>%
  ggplot(aes(x = both_SAT)) + 
  geom_histogram(binwidth=20)

  df_composite %>% 
  ggplot(aes(x = high_GPA)) +
  geom_histogram(binwidth=0.2)
  
  df_composite %>% 
  ggplot(aes(x = univ_GPA)) +
  geom_histogram(binwidth = 0.2)
  
histo_SAT  
```

**Observations**:

-   To what extent does `both_SAT` look like a normal distribution?
    -   both_SAT doesn't really look like a normal distribution. We see
        a dip at both ends which we would see with a normal
        distribution, but there are many dips in the distribution. By
        decreasing the number of bins, it begins to look somewhat more
        normal and it definitely has an element of symmetry to it. That
        being said, there isn't an obvious normal distribution in this
        graph.
-   To what extent does `high_GPA` look like a normal distribution?
    -   Out of the three graphs, high school GPA looks the most similar
        to a normal distribution. We see the left half increasing and
        the right half decreasing in count. That being said, we also see
        a dip around a 3.0 high school GPA. This makes it appear less as
        a normal distribution, but it is more visibly similar than the
        other graphs constructed.
-   To what extent does `univ_GPA` look like a normal distribution?
    -   This distribution looks like it is skewed left with the counts
        on the left being relatively low and increasing on the right
        before decreasing. This definitely does not look like a normal
        distribution as it looks very similar to a left skewed
        distribution.

Keep in mind your findings as you complete q4.

### **q4** Use the function `cor.test()` to construct confidence intervals for `corr[high_GPA, univ_GPA` and `corr[both_SAT, univ_GPA]`. Answer the questions below.

```{r q4-task}
## TODO: Use the function cor.test() to test the correlations between
##       high_GPA and univ_GPA, as well as between
##       both_SAT and univ_GPA
conf_int_gpa <-
  cor.test(df_composite$high_GPA, df_composite$univ_GPA)
conf_int_gpa

conf_int_sat <-
  cor.test(df_composite$both_SAT, df_composite$univ_GPA)
conf_int_sat
```

**Observations**:

-   Which correlations are significantly nonzero?
    -   Both correlations are significantly nonzero. The correlation
        between SAT and university GPA is approximately 0.685 and the
        correlation between high school GPA and university GPA is
        approximately 0.78. We know that the correlations are
        signficantly nonzero and statisitically significant because
        neither confidence interval includes zero.
-   Which of `high_GPA` and `both_SAT` seems to be more strongly
    correlated with `univ_GPA`?
    -   There seems to be a stronger correlation between high_GPA and
        univ_GPA than between both_SAT and univ_GPA. This is because we
        see a stronger correlation value and a confidence interval with
        a higher range of values from looking at the correlation between
        high_GPA and univ_GPA.
-   How do the results here compare with the visual you created in q2?
    -   These results line up pretty accurately with the visual I
        created in q2. With the SAT and university GPA, we see that the
        points for a stronger correlation than with high school GPA and
        university GPA. That being said, the difference is not largely
        noticeable which is explained through the difference in
        correlation only being about 0.1.
-   Based on these results, what can we say about the predictive
    capabilities of both `high_GPA` and `both_SAT` to predict
    `univ_GPA`?
    -   High school GPA and SAT scores can be loosely used to predict a
        student's university GPA. That being said, a student's SAT score
        will be more likely to accurately predict a student's university
        GPA. Neither should be used to definitively state the university
        GPA of a student as there is not enough correlation to have such
        confidence.

Finally, let's use the bootstrap to perform the same test using
*different* assumptions.

### **q5** Use the bootstrap to approximate a confidence interval for `corr[high_GPA, univ_GPA`. Compare your results---both the estimate and confidence interval---to your results from q4.

```{r q5-task}
## TODO: Use the bootstrap to compute a confidence interval for corr[high_GPA, univ_GPA]
set.seed(101)

corr_score <- function(splits, ...) {
  df <- analysis(splits)
  tibble(
    term = "gpa_compare",
    estimate = cor.test(df$high_GPA, df$univ_GPA)$estimate
  )
}

boots <-
  df_composite %>%
  bootstraps(times = 1000) %>% 
  mutate(estimates = map_dfr(splits, corr_score)) %>% 
  int_pctl(estimates)
boots
```

**Observations**:

-   How does your estimate from q5 compare with your estimate from q4?
    -   My estimate from q5 is 0.7798 while my estimate from q4 is about
        0.7796. These are very close to one another with my estimate
        from q5 showing slightly more correlation between the two
        variables.
-   How does your CI from q5 compare with your CI from q4?
    -   My confidence interval from q5 is [0.6933, 0.8477] while my
        confidence interval from q4 is [0.6912, 0.8450]. The range of
        the confidence intervals for the questions are nearly the same,
        with q5 having a higher lower bound and a higher upper bound.

*Aside*: When you use two different approximations to compute the same
quantity and get similar results, that's an *encouraging sign*. Such an
outcome lends a bit more credibility to the results.

## View 2: Modeling

<!-- ------------------------- -->

Correlations are useful for relating two variables at a time. To study
the relationship among more variables we can instead use a fitted model.
Using a model, we can also help assess whether it is *worthwhile* to
measure a variable.

To begin, let's first split the data into training and validation sets.

```{r split}
## NOTE: No need to edit
set.seed(101)

df_train <-
  df_composite %>%
  rowid_to_column() %>%
  slice_sample(n = 80)

df_validate <-
  df_composite %>%
  rowid_to_column() %>%
  anti_join(
    .,
    df_train,
    by = "rowid"
  )
```

### Hypothesis Testing with a Model

<!-- ------------------------- -->

We can combine the ideas of hypothesis testing with a model. Using a
model, we can express our hypotheses in terms of the model parameters.
For instance, if we were interested in whether $X$ has an affect on $Y$,
we might set up a model:

$$Y_i = \beta X_i + \epsilon_i$$

With the hypotheses:

$$\text{H0}: \beta = 0$$

$$\text{HA}: \beta \neq 0$$

In this case, we're testing for whether $X$ has a significant effect on
$Y$. Let's apply this idea to relating the variables `univ_GPA` and
`high_GPA`. Luckily R has built-in tools to construct a confidence
interval on the $\beta$'s in a regression [1]; we'll simply use those
tools rather than do it by hand.

### **q6** Fit a linear model predicting `univ_GPA` with the predictor `both_SAT`. Assess the model to determine how effective a predictor `both_SAT` is for `univ_GPA`. Interpret the resulting confidence interval for the coefficient on `both_SAT`.

```{r q6-task}
## TODO: Fit a model of univ_GPA on the predictor both_SAT
fit_uni_sat <-
    df_train %>%
    lm(
      data = .,
      formula = univ_GPA ~ both_SAT
    )

## NOTE: The following computes confidence intervals on regression coefficients
fit_uni_sat %>%
  tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
```

**Observations**:

-   What is the confidence interval on the coefficient of `both_SAT`? Is
    this coefficient significantly different from zero?
    -   The confidence interval on the coefficient of both_SAT is
        [0.00172, 0.00342]. This coefficient (.00257) is signficantly
        different from zero and statistically significant due to the
        fact that the confidence interval does not include zero.
-   By itself, how well does `both_SAT` predict `univ_GPA`?
    -   By itself, both_SAT does not predict univ_GPA very well since we
        got a coefficient that is very low showing that both_SAT is not
        a great predictor.

Remember from `e-model03-interp-warnings` that there are challenges with
interpreting regression coefficients! Let's investigate that idea
further.

### **q7** Fit a model predicting `univ_GPA` using both `high_GPA` and `both_SAT`. Compare the prediction accuracy and hypothesis test results.

```{r q7-task}
## TODO: Fit and assess models with predictors both_SAT + high_GPA, and high_GPA alone
fit_uni_high_sat <-
    df_train %>%
    lm(
      data = .,
      formula = univ_GPA ~ both_SAT + high_GPA
    ) %>% 
    tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
fit_uni_high_sat

fit_uni_high <-
    df_train %>%
    lm(
      data = .,
      formula = univ_GPA ~ high_GPA
    ) %>% 
    tidy(
    conf.int = TRUE,
    conf.level = 0.99
  )
fit_uni_high
```

**Observations**:

-   How well do these models perform, compared to the one you built in
    q6?
    -   The model predicting univ_GPA with high_GPA and both_SAT does
        not perform as well for both_SAT as the model in q6 since this
        model yields a coefficient that is not significantly different
        from zero. That being said, this model also shows how well
        high_GPA predicts univ_GPA which is something the previous model
        in q6 did not.
-   What is the confidence interval on the coefficient of `both_SAT`
    when including `high_GPA` as a predictor?? Is this coefficient
    significantly different from zero?
    -   The confidence interval is [-0.00067, 0.00174] on the
        coefficient of both_SAT including high_GPA as a predictor. The
        coefficient estimate (0.000534) is not significantly different
        from zero because the confidence interval includes zero.
-   How do the hypothesis test results compare with the results in q6?
    -   The test results for both_SAT and high_GPA as predictors for
        univ_GPA while looking at both_SAT shows that the coefficient is
        not significantly different from zero. high_GPA alone and paired
        with both_SAT as a predictor is significantly different from
        zero. This differs from q6 that showed that both_SAT as a
        predictor is significantly different from zero.

## Synthesize

<!-- ------------------------- -->

Before closing, let's synthesize a bit from the analyses above.

### **q8** Using the results from all previous q's, answer the following questions.

**Observations**:

-   Between `both_SAT` and `high_GPA`, which single variable would you
    choose to predict `univ_GPA`? Why?
    -   I would use high_GPA to predict univ_GPA because we found that
        the correlation between high_GPA and univ_GPA was stronger than
        the correlation between both_SAT and univ_GPA. This would give
        me more confidence that high school GPA is a stronger predictor
        of one's university GPA than the SAT score.
-   Is `both_SAT` an effective predictor of `univ_GPA`? What specific
    pieces of evidence do you have in favor of `both_SAT` being
    effective? What specific pieces of evidence do you have against?
    -   Generally, I would say that both_SAT is not an effective
        predictor of univ_GPA. We have the Pearson's correlation that is
        in favor of both_SAT being effective, having a value of around
        0.685. That being said, in q6 and q7 we found that both_SAT was
        not a good predictor and in q7 we found that the correlation
        value was not signficantly different from zero. This would lead
        me to conclude that both_SAT should not be used as a predictor
        of univ_GPA.

# End Notes

<!-- ----------------------------------------------------------------------- -->

[1] There are also assumptions underlying this kind of testing, for more
information see this [Wiki
article](https://en.wikipedia.org/wiki/Linear_regression#Assumptions).
