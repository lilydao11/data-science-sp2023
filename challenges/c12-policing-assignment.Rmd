---
title: "Massachusetts Highway Stops"
author: "Lily Dao"
date: 2023-04-24
output:
  github_document:
    toc: true
---

*Purpose*: In this last challenge we'll focus on using logistic regression to study a large, complicated dataset. Interpreting the results of a model can be challenging---both in terms of the statistics and the real-world reasoning---so we'll get some practice in this challenge.

<!-- include-rubric -->

# Grading Rubric

<!-- -------------------------------------------------- -->

Unlike exercises, **challenges will be graded**. The following rubrics define how you will be graded, both on an individual and team basis.

## Individual

<!-- ------------------------- -->

| Category    | Needs Improvement                                                                                                | Satisfactory                                                                                                               |
|------------------|--------------------------|----------------------------|
| Effort      | Some task **q**'s left unattempted                                                                               | All task **q**'s attempted                                                                                                 |
| Observed    | Did not document observations, or observations incorrect                                                         | Documented correct observations based on analysis                                                                          |
| Supported   | Some observations not clearly supported by analysis                                                              | All observations clearly supported by analysis (table, graph, etc.)                                                        |
| Assessed    | Observations include claims not supported by the data, or reflect a level of certainty not warranted by the data | Observations are appropriately qualified by the quality & relevance of the data and (in)conclusiveness of the support      |
| Specified   | Uses the phrase "more data are necessary" without clarification                                                  | Any statement that "more data are necessary" specifies which *specific* data are needed to answer what *specific* question |
| Code Styled | Violations of the [style guide](https://style.tidyverse.org/) hinder readability                                 | Code sufficiently close to the [style guide](https://style.tidyverse.org/)                                                 |

## Due Date

<!-- ------------------------- -->

All the deliverables stated in the rubrics above are due **at midnight** before the day of the class discussion of the challenge. See the [Syllabus](https://docs.google.com/document/d/1qeP6DUS8Djq_A0HMllMqsSqX3a9dbcx1/edit?usp=sharing&ouid=110386251748498665069&rtpof=true&sd=true) for more information.

*Background*: We'll study data from the [Stanford Open Policing Project](https://openpolicing.stanford.edu/data/), specifically their dataset on Massachusetts State Patrol police stops.

```{r setup}
library(tidyverse)
library(broom)
library(ggplot2)
```

# Setup

<!-- -------------------------------------------------- -->

### **q1** Go to the [Stanford Open Policing Project](https://openpolicing.stanford.edu/data/) page and download the Massachusetts State Police records in `Rds` format. Move the data to your `data` folder and match the `filename` to load the data.

*Note*: An `Rds` file is an R-specific file format. The function `readRDS` will read these files.

```{r q1-task}
## TODO: Download the data, move to your data folder, and load it
filename <- NA_character_
df_data <- readRDS("./data/ma_statewide_2020_04_01.rds")
df_data
```

# EDA

<!-- -------------------------------------------------- -->

### **q2** Do your "first checks" on the dataset. What are the basic facts about this dataset?

```{r q2-task}
glimpse(df_data)
summary(df_data)
```

Note that we have both a `subject_race` and `race_Raw` column. There are a few possibilities as to what `race_Raw` represents:

-   `race_Raw` could be the race of the police officer in the stop
-   `race_Raw` could be an unprocessed version of `subject_race`

Let's try to distinguish between these two possibilities.

### **q3** Check the set of factor levels for `subject_race` and `raw_Race`. What do you note about overlap / difference between the two sets?

```{r q3-task}
## TODO: Determine the factor levels for subject_race and raw_Race

df_data %>%
  pull(subject_race) %>%
  levels()
levels(as.factor(df_data$raw_Race))
```

**Observations**:

-   What are the unique values for `subject_race`?

    The unique values for subject_race are "other" and "unknown".

-   What are the unique values for `raw_Race`?

    The unique values for raw_Race are "A", "American Indian or Alaskan Native", "Middle Eastern or East Indian (South Asian)", and "None - for no operator present citations only".

-   What is the overlap between the two sets?

    The values that overlap are "asian/pacific islander", "black", "hispanic", and "white".

-   What is the difference between the two sets?

    The difference between the two sets is that raw_Race has a few more categories like "A", "American Indian or Alaskan Native", "Middle Eastern or East Indian (South Asian)". While raw_Race has "None - for not operator present citations only", subject_race has "other" and "unknown".

### **q4** Check whether `subject_race` and `raw_Race` match for a large fraction of cases. Which of the two hypotheses above is most likely, based on your results?

*Note*: Just to be clear, I'm *not* asking you to do a *statistical* hypothesis test.

```{r q4-task}
## TODO: Devise your own way to test the hypothesis posed above.
df_data["raw_Race"][df_data["raw_Race"] == "Asian or Pacific Islander"] <- "asian/pacific islander"
df_data["raw_Race"][df_data["raw_Race"] == "American Indian or Alaskan Native"] <- "other"
df_data["raw_Race"][df_data["raw_Race"] == "A"] <- "other"
df_data["raw_Race"][df_data["raw_Race"] == "Middle Eastern or East Indian (South Asian)"] <- "other"
df_data["raw_Race"][df_data["raw_Race"] == "None - for no operator present citations only"] <- "unknown"
df_data$raw_Race <- tolower(df_data$raw_Race)
```

```{r}
df_data %>% 
  summarise(raw_Race, subject_race)
summary(df_data$subject_race == df_data$raw_Race)
```

**Observations**

Between the two hypotheses:

-   `race_Raw` could be the race of the police officer in the stop
-   `race_Raw` could be an unprocessed version of `subject_race`

which is most plausible, based on your results?

-   It seems that the most plausible hypothesis is that race_Raw is the unprocessed version of subject_race. This is because around 97.3% of the values match between subject_race and race_Raw after I processed race_Raw a bit to fall into the categories of subject_race.

## Vis

<!-- ------------------------- -->

### **q5** Compare the *arrest rate*---the fraction of total cases in which the subject was arrested---across different factors. Create as many visuals (or tables) as you need, but make sure to check the trends across all of the `subject` variables. Answer the questions under *observations* below.

(Note: Create as many chunks and visuals as you need)

```{r}
totals_added_sex <-
  df_data %>% 
    group_by(subject_sex, outcome) %>% 
    mutate(n = n()) %>%
    ungroup() %>% 
    group_by(subject_sex) %>% 
    mutate(total = n()) %>% 
    summarise(subject_sex, outcome, n, total) %>% 
    distinct() %>% 
    mutate(arrest_rate = n / total) %>% 
    filter(outcome == "arrest")
totals_added_sex

totals_added_sex %>% 
  ggplot(mapping = aes(subject_sex, arrest_rate))+
  geom_col()

totals_added_race <-
  df_data %>% 
    group_by(subject_race, outcome) %>% 
    mutate(n = n()) %>%
    ungroup() %>% 
    group_by(subject_race) %>% 
    mutate(total = n()) %>% 
    summarise(subject_race, outcome, n, total) %>% 
    distinct() %>% 
    mutate(arrest_rate = n / total) %>% 
    filter(outcome == "arrest")
totals_added_race

totals_added_race %>% 
  ggplot(mapping = aes(subject_race, arrest_rate))+
  geom_col()

totals_added_age <-
  df_data %>% 
    group_by(subject_age, outcome) %>% 
    mutate(n = n()) %>%
    ungroup() %>% 
    group_by(subject_age) %>% 
    mutate(total = n()) %>% 
    summarise(subject_age, outcome, n, total) %>% 
    distinct() %>% 
    mutate(arrest_rate = n / total) %>% 
    filter(outcome == "arrest")
totals_added_age

totals_added_age %>% 
  ggplot(mapping = aes(subject_age, arrest_rate))+
  geom_col()

```

**Observations**:

-   How does `arrest_rate` tend to vary with `subject_age`?
    -   We see that arrest rate peaks around age 15 then dramatically drops off around the age of 20. From there, we see a rise in arrest rate as someone gets older between around 20 and 27, then we see a steady decrease in arrest rate. At over 85 years old, we see another peak, but this could be due to the small sample size of older folks that were stopped.
-   How does `arrest_rate` tend to vary with `subject_sex`?
    -   From this data set, we see that the arrest rate is double for males than for females for the subject_sex variable. Furthermore, those with a recorded subject_sex of NA have less than half the arrest rate than females.
-   How does `arrest_rate` tend to vary with `subject_race`?
    -   We see that the arrest rate is the highest for Hispanic people at nearly 6%. The arrest rate for black people follows with around 3.5%, with other, NA, and white sitting at 2-3%. White, Asian/Pacific Islander, and unknown race are lowest three in terms of arrest rate. The unknown rate being so low may be due to an officer not being present at the time of the stop.

# Modeling

<!-- -------------------------------------------------- -->

We're going to use a model to study the relationship between `subject` factors and arrest rate, but first we need to understand a bit more about *dummy variables*

### **q6** Run the following code and interpret the regression coefficients. Answer the the questions under *observations* below.

```{r q6-task}
## NOTE: No need to edit; inspect the estimated model terms.
fit_q6 <-
  glm(
    formula = arrest_made ~ subject_age + subject_race + subject_sex,
    data = df_data %>%
      filter(
        !is.na(arrest_made),
        subject_race %in% c("white", "black", "hispanic")
      ),
    family = "binomial"
  )

fit_q6 %>% tidy()
```

**Observations**:

-   Which `subject_race` levels are included in fitting the model?
    -   The subject_race levels included in fitting the model are white, black, and hispanic.
-   Which `subject_race` levels have terms in the model?
    -   The subject_race levels that have terms in the model are hispanic and white.

You should find that each factor in the model has a level *missing* in its set of terms. This is because R represents factors against a *reference level*: The model treats one factor level as "default", and each factor model term represents a change from that "default" behavior. For instance, the model above treats `subject_sex==male` as the reference level, so the `subject_sexfemale` term represents the *change in probability* of arrest due to a person being female (rather than male).

The this reference level approach to coding factors is necessary for [technical reasons](https://www.andrew.cmu.edu/user/achoulde/94842/lectures/lecture10/lecture10-94842.html#why-is-one-of-the-levels-missing-in-the-regression), but it complicates interpreting the model results. For instance; if we want to compare two levels, neither of which are the reference level, we have to consider the difference in their model coefficients. But if we want to compare all levels against one "baseline" level, then we can relevel the data to facilitate this comparison.

By default `glm` uses the first factor level present as the reference level. Therefore we can use `mutate(factor = fct_relevel(factor, "desired_level"))` to set our `"desired_level"` as the reference factor.

### **q7** Re-fit the logistic regression from q6 setting `"white"` as the reference level for `subject_race`. Interpret the the model terms and answer the questions below.

```{r q7-task}
## TODO: Re-fit the logistic regression, but set "white" as the reference
## level for subject_race
df_data$subject_race <- relevel(df_data$subject_race, ref = "white")

fit_q7 <-
    glm(
    formula = arrest_made ~ subject_race + subject_age + subject_sex,
    data = df_data %>%
      filter(
        !is.na(arrest_made),
        subject_race %in% c("white", "black", "hispanic", "other", "asian/pacific islander", "unknown", "NA")
      ),
    family = "binomial"
  )


fit_q7 %>% tidy()
```

**Observations**:

-   Which `subject_race` level has the highest probability of being arrested, according to this model? Which has the lowest probability?
    -   The subject_race level with the highest probability of being arrested (from this model) is Hispanic. The level with the lowest probability is unknown, with the lowest probability of a known race being Asian/Pacific Islander.
-   What could explain this difference in probabilities of arrest across race? List **multiple** possibilities.
    -   Officer bias
    -   Contraband presence
    -   Age/sex, since this isn't fully accounted for
    -   County/location
    -   Interaction between officer and person stopped
-   Look at the sent of variables in the dataset; do any of the columns relate to a potential explanation you listed?
    -   We have many columns that cover the presence of contraband, we also have subject age and sex which we have looked at. Lastly, from my list, we have the location of the traffic stop.

One way we can explain differential arrest rates is to include some measure indicating the presence of an arrestable offense. We'll do this in a particular way in the next task.

### **q8** Re-fit the model using a factor indicating the presence of contraband in the subject's vehicle. Answer the questions under *observations* below.

```{r q8-task}
## TODO: Repeat the modeling above, but control for whether contraband was found
## during the police stop

fit_q8 <-
    glm(
    formula = arrest_made ~ subject_race + subject_age + subject_sex + contraband_found,
    data = df_data %>%
      filter(
        !is.na(arrest_made),
        subject_race %in% c("white", "black", "hispanic", "other", "asian/pacific islander", "unknown", "NA")
      ),
    family = "binomial"
  )

fit_q8 %>% tidy()
```

**Observations**:

-   How does controlling for found contraband affect the `subject_race` terms in the model?

    When we are controlling for contraband found, we see that the probability of arrest for each race decreases except for Asian/Pacific Islander. It seems that when we are controlling for contraband, it is when contraband found. This makes sense since when we see filter that contraband is not found, we should see less arrests across the board.

-   What does the *finding of contraband* tell us about the stop? What does it *not* tell us about the stop?

    The finding of contraband tells us that the person stopped was searched. It also tells us that there was a basis for the search. Whether this is a valid basis or not is something we don't know. Finding of contraband also indicates that there was an officer present to find the contraband.

### **q9** Go deeper: Pose at least one more question about the data and fit at least one more model in support of answering that question.

```{r}
fit_q9 <-
    glm(
    formula = arrest_made ~ subject_race + subject_age + subject_sex + search_conducted,
    data = df_data %>%
      filter(
        !is.na(arrest_made),
        subject_race %in% c("white", "black", "hispanic", "other", "asian/pacific islander", "unknown", "NA")
      ),
    family = "binomial"
  )

fit_q9 %>% tidy()
```

**Observations**:

-   I was asking the question: How does search being conducted or not affect the probability of arrest for different races or sexes compared to search not being factored in?
-   By looking at this model and comparing the values to the model without search being factored in, I noticed that not much had changed. I noticed that the "other" race category has a lower probability of race by over 0.1. The female sex category has a slightly higher probability of arrest with the search being factored in increasing by around 0.1. When search is factored in, the probability of arrest for the other categories is not notably changed. That being said, we do see that when a search is conducted, the probability of arrest is significantly higher for that factor than any of the other factors.

Just an interesting graph plotting the normalized value of probable cause search basis instances vs. race and an normalized value of probable cause search base instances that also led to arrest vs. race.

```{r}
# Graph showing the searches on the basis of "probable cause" normalized by all stops vs. race. 
df_graph <-
  df_data %>% 
    group_by(subject_race) %>% 
    summarise(
      n_prob_cause = sum(search_basis == 'probable cause', na.rm = TRUE),
      n_total = n(),
      n_prob_cause_arrest = sum(search_basis == 'probable cause'& outcome == "arrest", na.rm = TRUE)
    ) %>% 
    mutate(cause_norm = n_prob_cause/n_total) %>% 
    mutate(cause_norm_arrest = n_prob_cause_arrest/n_total) %>% 
    filter(!row_number() %in% c(7)) %>% 
    pivot_longer(
      cols = c(cause_norm, cause_norm_arrest),
      names_to = c("quantity"),
      values_to = c("fraction")
    )
df_graph
df_graph %>% 
  ggplot() +
  geom_col(mapping = aes(subject_race, fraction))+
  facet_wrap(~ quantity)
```

## Further Reading

<!-- -------------------------------------------------- -->

-   Stanford Open Policing Project [findings](https://openpolicing.stanford.edu/findings/).
